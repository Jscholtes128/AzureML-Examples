{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Experiment\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "import pandas as pd\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import average_precision_score,accuracy_score,f1_score,classification_report,precision_recall_curve,confusion_matrix,roc_auc_score,precision_score, recall_score,roc_curve\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from azureml.core.experiment import Experiment\r\n",
        "from azureml.core.workspace import Workspace,Dataset\r\n",
        "from sklearn.externals import joblib\r\n",
        "import sys"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n  warnings.warn(msg, category=FutureWarning)\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1635361574137
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\r\n",
        "n_estimators = 10"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635361575037
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Dataset.get_by_name(ws, name='Churn Databricks')\r\n",
        "train = dataset.to_pandas_dataframe()"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635361651094
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "experiment = Experiment(ws, 'churn-classifier')\r\n",
        "\r\n",
        "\r\n",
        "run =  experiment.start_logging()\r\n",
        "run.tag(\"python version\", sys.version[0:6])\r\n",
        "run.log('n_estimators', n_estimators)\r\n",
        "\r\n",
        "X = train.drop('Exited', axis=1)\r\n",
        "y = train['Exited']\r\n",
        "\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'customerchurn.zip'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-0fd865106bcb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_logging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"python version\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'n_estimators'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/experiment.py\u001b[0m in \u001b[0;36mstart_logging\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \"\"\"\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mazureml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mRun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_logging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_parent_logger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_check_for_experiment_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/run.py\u001b[0m in \u001b[0;36m_start_logging\u001b[0;34m(experiment, name, run_id, outputs, snapshot_directory, **kwargs)\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msnapshot_directory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m                 \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake_snapshot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msnapshot_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mSnapshotException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msnapshot_ex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m                 \u001b[0merror_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Failed to take a snapshot of {}. Pass snapshot_directory=None to start_logging \"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/run.py\u001b[0m in \u001b[0;36mtake_snapshot\u001b[0;34m(self, file_or_folder_path)\u001b[0m\n\u001b[1;32m   2150\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2151\u001b[0m         \"\"\"\n\u001b[0;32m-> 2152\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake_snapshot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_or_folder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrestore_snapshot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msnapshot_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_run_impl/run_history_facade.py\u001b[0m in \u001b[0;36mtake_snapshot\u001b[0;34m(self, file_or_folder_path, _raise_on_validation_failure)\u001b[0m\n\u001b[1;32m    684\u001b[0m             snapshot_id = self.snapshots.create_snapshot(\n\u001b[1;32m    685\u001b[0m                 \u001b[0mfile_or_folder_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m                 raise_on_validation_failure=_raise_on_validation_failure)\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m             \u001b[0mslcx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Created snapshot {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msnapshot_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_restclient/snapshots_client.py\u001b[0m in \u001b[0;36mcreate_snapshot\u001b[0;34m(self, file_or_folder_path, retry_on_failure, raise_on_validation_failure)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# Compute the dir tree for the current working set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mcurr_root\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_merkletree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_or_folder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;31m# Compute the diff between the two dirTrees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_base_sdk_common/merkle_tree.py\u001b[0m in \u001b[0;36mcreate_merkletree\u001b[0;34m(file_or_folder_path, exclude_function)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_or_folder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mfolder_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_or_folder_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0m_create_merkletree_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_or_folder_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_base_sdk_common/merkle_tree.py\u001b[0m in \u001b[0;36m_create_merkletree_helper\u001b[0;34m(projectDir, rootNode, exclude_function)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprojectDir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0mnewNode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDirTreeNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"File\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromtimestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misoformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                 \u001b[0mhexdigest_hash\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytehash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"File\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhexdigest_hash\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbytehash\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                     \u001b[0mnewNode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhexdigest_hash\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytehash\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_base_sdk_common/merkle_tree.py\u001b[0m in \u001b[0;36m_get_hash\u001b[0;34m(filePath, name, file_type)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot access file, so excluded from snapshot: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilePath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilePath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHASH_FILE_CHUNK_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'customerchurn.zip'"
          ]
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635187233820
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sklearn Pipeline"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\r\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\r\n",
        "from sklearn.impute import SimpleImputer\r\n",
        "from sklearn.decomposition import TruncatedSVD\r\n",
        "from sklearn.compose import ColumnTransformer\r\n",
        "\r\n",
        "\r\n",
        "numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns\r\n",
        "categorical_features = X_train.select_dtypes(include=['object']).columns\r\n",
        "\r\n",
        "rf = RandomForestClassifier(n_estimators=n_estimators)\r\n",
        "\r\n",
        "numeric_transformer = Pipeline(steps=[\r\n",
        "    ('imputer', SimpleImputer(strategy='median')),\r\n",
        "    ('scaler', StandardScaler())\r\n",
        "])\r\n",
        "\r\n",
        "categorical_transformer = Pipeline(steps=[\r\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\r\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\r\n",
        "])\r\n",
        "\r\n",
        "preprocessor = ColumnTransformer(\r\n",
        "    transformers=[\r\n",
        "        ('num', numeric_transformer, numeric_features),\r\n",
        "        ('cat', categorical_transformer, categorical_features)\r\n",
        "    ])\r\n",
        "\r\n",
        "model = Pipeline(steps=[\r\n",
        "    ('precprocessor', preprocessor),\r\n",
        "    ('classifier', rf)\r\n",
        "])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635188277741
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Model Pipeline and log experiment metrics"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,y_train)\r\n",
        "\r\n",
        "y_pred = model.predict(X_test)\r\n",
        "train_probs = model.predict_proba(X_train)[:,1] \r\n",
        "probs = model.predict_proba(X_test)[:, 1]\r\n",
        "train_predictions = model.predict(X_train)\r\n",
        "\r\n",
        "run.log(\"accuracy\",accuracy_score(y_test, y_pred))\r\n",
        "run.log(\"auc\",roc_auc_score(y_test, probs))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635188291509
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate and log ROC Plot"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "def evaluate_model(y_pred, probs,train_predictions, train_probs):\r\n",
        "    baseline = {}\r\n",
        "    baseline['recall']=recall_score(y_test,\r\n",
        "                    [1 for _ in range(len(y_test))])\r\n",
        "    baseline['precision'] = precision_score(y_test,\r\n",
        "                    [1 for _ in range(len(y_test))])\r\n",
        "    baseline['roc'] = 0.5\r\n",
        "    results = {}\r\n",
        "    results['recall'] = recall_score(y_test, y_pred)\r\n",
        "    results['precision'] = precision_score(y_test, y_pred)\r\n",
        "    results['roc'] = roc_auc_score(y_test, probs)\r\n",
        "    train_results = {}\r\n",
        "    train_results['recall'] = recall_score(y_train,       train_predictions)\r\n",
        "    train_results['precision'] = precision_score(y_train, train_predictions)\r\n",
        "    train_results['roc'] = roc_auc_score(y_train, train_probs)\r\n",
        "\r\n",
        "    base_fpr, base_tpr, _ = roc_curve(y_test, [1 for _ in range(len(y_test))])\r\n",
        "    model_fpr, model_tpr, _ = roc_curve(y_test, probs)\r\n",
        "    plt.figure(figsize = (8, 6))\r\n",
        "    plt.rcParams['font.size'] = 16\r\n",
        "    # Plot both curves\r\n",
        "    plt.plot(base_fpr, base_tpr, 'b', label = 'baseline')\r\n",
        "    plt.plot(model_fpr, model_tpr, 'r', label = 'model')\r\n",
        "    plt.legend();\r\n",
        "    plt.xlabel('False Positive Rate');\r\n",
        "    plt.ylabel('True Positive Rate'); plt.title('ROC Curves');\r\n",
        "    run.log_image('ROC', path=None, plot=plt, description='ROC Curve')\r\n",
        "    plt.show();"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635188316295
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(y_pred,probs,train_predictions,train_probs)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635188323292
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use interpretability package to explain ML models & predictions"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.interpret import ExplanationClient\r\n",
        "from interpret.ext.blackbox import TabularExplainer\r\n",
        "\r\n",
        "\r\n",
        "client = ExplanationClient.from_run(run)\r\n",
        "explainer = TabularExplainer(model, \r\n",
        "                             X_train)\r\n",
        "\r\n",
        "# explain overall model predictions (global explanation)\r\n",
        "global_explanation = explainer.explain_global(X_test)\r\n",
        "\r\n",
        "# uploading global model explanation data for storage or visualization in webUX\r\n",
        "# the explanation can then be downloaded on any compute\r\n",
        "# multiple explanations can be uploaded\r\n",
        "client.upload_model_explanation(global_explanation, comment='global explanation: all features')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635189810733
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_file_name = 'outputs/model.pkl'\r\n",
        "\r\n",
        "joblib.dump(value = model, filename = model_file_name)\r\n",
        "run.complete()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635189812124
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}