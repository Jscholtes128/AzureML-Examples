{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace\r\n",
        "from azureml.core import Experiment, Environment\r\n",
        "from azureml.pipeline.core import Pipeline\r\n",
        "from azureml.data.data_reference import DataReference\r\n",
        "from azureml.core.compute import AmlCompute, ComputeTarget\r\n",
        "from azureml.core.runconfig import RunConfiguration\r\n",
        "from modules.ingestion.data_ingestion_step import data_ingestion_step\r\n",
        "from modules.preprocess.data_preprocess_step import data_preprocess_step\r\n",
        "from modules.train.train_step import train_step\r\n",
        "from modules.evaluate.evaluate_step import evaluate_step\r\n",
        "from modules.deploy.deploy_step import deploy_step\r\n",
        "import json"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1632493156550
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\r\n",
        "\r\n",
        "datastore = ws.get_default_datastore()\r\n",
        "\r\n",
        "datastore = DataReference(datastore, mode='mount')"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1632493160697
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create CPU compute target\r\n",
        "print('Creating CPU compute target ...')\r\n",
        "cpu_cluster_name = 'cpuclst'\r\n",
        "cpu_compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS3_V2', \r\n",
        "                                                           idle_seconds_before_scaledown=1200,\r\n",
        "                                                           min_nodes=0, \r\n",
        "                                                           max_nodes=2)\r\n",
        "cpu_compute_target = ComputeTarget.create(ws, cpu_cluster_name, cpu_compute_config)\r\n",
        "cpu_compute_target.wait_for_completion(show_output=True)\r\n",
        "\r\n",
        "\r\n",
        "aml_run_config = RunConfiguration()\r\n",
        "aml_run_config.target = cpu_compute_target\r\n",
        "curated_environment = Environment.get(workspace=ws, name=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu\")\r\n",
        "aml_run_config.environment = curated_environment"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Creating CPU compute target ...\nSucceededProvisioning operation finished, operation \"Succeeded\"\nSucceeded\nAmlCompute wait for completion finished\n\nMinimum number of nodes requested have been provisioned\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1632493162102
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Data ingestion \r\n",
        "data_ingestion_step, data_ingestion_outputs = data_ingestion_step(datastore, cpu_compute_target,aml_run_config)\r\n",
        "\r\n",
        "# Step 2: Data preprocessing \r\n",
        "data_preprocess_step, data_preprocess_outputs = data_preprocess_step(data_ingestion_outputs['raw_data_dir'], cpu_compute_target,aml_run_config)\r\n",
        "\r\n",
        "# Step 3: Train Model\r\n",
        "train_step, train_outputs = train_step(data_preprocess_outputs['train_dir'], cpu_compute_target,aml_run_config)\r\n",
        "\r\n",
        "# Step 4: Evaluate Model\r\n",
        "evaluate_step, evaluate_outputs = evaluate_step(train_outputs['model_dir'], data_preprocess_outputs['test_dir'], cpu_compute_target,aml_run_config)\r\n",
        "\r\n",
        "# Step 5: Deploy Model\r\n",
        "deploy_step, deploy_outputs = deploy_step(train_outputs['model_dir'], evaluate_outputs['accuracy_file'], data_preprocess_outputs['test_dir'], cpu_compute_target,aml_run_config)\r\n"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1632493162271
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit pipeline\r\n",
        "print('Submitting pipeline ...')\r\n",
        "pipeline_parameters = {\r\n",
        "    'max_depth': 5,\r\n",
        "    'n_estimators': 500\r\n",
        "}\r\n",
        "\r\n",
        "\r\n",
        "# Submit pipeline\r\n",
        "print('Submitting pipeline ...')\r\n",
        "\r\n",
        "pipeline = Pipeline(workspace=ws, steps=[data_ingestion_step,data_preprocess_step,train_step,evaluate_step,deploy_step])\r\n",
        "pipeline_run = Experiment(ws, 'turbofan-pipeline').submit(pipeline, pipeline_parameters=pipeline_parameters)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Submitting pipeline ...\nSubmitting pipeline ...\nCreated step data_ingestion.py [2114da2e][220732fc-0c17-48ed-89e0-755abd2fd5bc], (This step is eligible to reuse a previous run's output)\nCreated step data_preprocess.py [24e81e4f][8d9886af-fd15-499f-93f5-a8cd371311d0], (This step is eligible to reuse a previous run's output)\nCreated step train_data [782006ce][f7a41189-1c85-46f5-bf94-74c85b15e0dd], (This step will run and generate new outputs)\nCreated step eval [c4d8a81d][429761eb-5e16-4f78-a025-bf0d82fca3a9], (This step will run and generate new outputs)\nCreated step deploy.py [2a337fff][2b92ad83-3433-47ed-9e31-f4f567f18e64], (This step will run and generate new outputs)\nUsing data reference workspaceblobstore for StepId [9dd9e562][b870ed78-17e6-465d-8f70-e4d1545f7618], (Consumers of this data are eligible to reuse prior runs.)\nSubmitted PipelineRun bd8dbb2f-cf6e-4940-bce2-a1edc350f8e5\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/bd8dbb2f-cf6e-4940-bce2-a1edc350f8e5?wsid=/subscriptions/0a6d383c-9ce6-490d-89b8-47e6231192c3/resourcegroups/ai-workshop/workspaces/aiw-ml&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1632493170204
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}